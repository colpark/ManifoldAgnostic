{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SDF-Based Neural Field Diffusion: Training and Testing\n",
    "\n",
    "**Key Innovation**: Instead of directly predicting velocity `v(x,t)`, we predict a scalar distance field `f(x,t)` and derive velocity as `v = -∇_x f(x,t)`.\n",
    "\n",
    "## Benefits of SDF-Based Approach:\n",
    "\n",
    "1. **Smoother Training**: No directional discontinuities in the output\n",
    "2. **Implicit Surface**: At t=0, the SDF represents the learned shape\n",
    "3. **Natural Gradients**: Gradient of scalar field is inherently continuous\n",
    "4. **Same Capacity**: Mathematically equivalent expressiveness to direct velocity\n",
    "\n",
    "## Architecture:\n",
    "- DiT blocks with 3D RoPE, AdaLN, SwiGLU for global context\n",
    "- NerfBlocks (hyper-network) for local neural field\n",
    "- Output: scalar `f(x,t) ∈ ℝ` instead of vector `v(x,t) ∈ ℝ³`\n",
    "- Velocity: `v(x,t) = -∇_x f(x,t)` computed via autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Our modules\n",
    "from data.toy_data import get_all_generators, generate_multi_sphere_ring\n",
    "from src.models.sdf_field import SDFNeuralField, SDFFlowMatchingLoss\n",
    "from src.diffusion.flow_matching import FlowMatchingSampler\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Data\n",
    "SHAPES = ['multi_sphere_ring']  # 8 spheres in a ring with jitter\n",
    "N_POINTS = 512\n",
    "N_SAMPLES = 1000\n",
    "RANDOM_TRANSFORM = False  # multi_sphere has built-in variation\n",
    "\n",
    "# Model (SMALL for toy data)\n",
    "HIDDEN_SIZE = 128\n",
    "HIDDEN_SIZE_X = 32\n",
    "NUM_HEADS = 4\n",
    "NUM_BLOCKS = 6\n",
    "NUM_COND_BLOCKS = 2\n",
    "NERF_MLP_RATIO = 2\n",
    "MAX_FREQS = 6\n",
    "\n",
    "# Training\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EIKONAL_WEIGHT = 0.0  # Try 0.1 for SDF regularization\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Training on: {SHAPES}\")\n",
    "print(f\"Eikonal weight: {EIKONAL_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, shapes, n_samples, n_points, noise_std=0.001,\n",
    "                 random_transform=True, scale_range=(0.7, 1.3)):\n",
    "        self.shapes = shapes if isinstance(shapes, list) else [shapes]\n",
    "        self.n_samples = n_samples\n",
    "        self.n_points = n_points\n",
    "        self.noise_std = noise_std\n",
    "        self.random_transform = random_transform\n",
    "        self.scale_range = scale_range\n",
    "        \n",
    "        all_generators = get_all_generators()\n",
    "        self.generators = [all_generators[s] for s in self.shapes]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        generator = self.generators[idx % len(self.generators)]\n",
    "        pc = generator(n_points=self.n_points)\n",
    "        \n",
    "        if self.random_transform:\n",
    "            pc = pc.random_transform(rotate=True, scale_range=self.scale_range, anisotropic=True)\n",
    "        \n",
    "        pc = pc.normalize()\n",
    "        if self.noise_std > 0:\n",
    "            pc = pc.add_noise(self.noise_std)\n",
    "        return torch.tensor(pc.points, dtype=torch.float32)\n",
    "\n",
    "dataset = PointCloudDataset(SHAPES, N_SAMPLES, N_POINTS, random_transform=RANDOM_TRANSFORM)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Dataset: {N_SAMPLES} samples, {N_POINTS} points each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training samples\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "for i in range(4):\n",
    "    sample = dataset[i].numpy()\n",
    "    ax = fig.add_subplot(1, 4, i+1, projection='3d')\n",
    "    colors = sample[:, 2]\n",
    "    ax.scatter(sample[:, 0], sample[:, 1], sample[:, 2], \n",
    "               c=colors, cmap='viridis', s=3, alpha=0.7)\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.set_xlim([-1.2, 1.2])\n",
    "    ax.set_ylim([-1.2, 1.2])\n",
    "    ax.set_zlim([-1.2, 1.2])\n",
    "    ax.view_init(elev=20, azim=30 + i*20)\n",
    "\n",
    "plt.suptitle(f'Training Data: {SHAPES[0]} - Each sample has different sphere positions', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. SDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SDF model (outputs scalar, velocity via gradient)\n",
    "model = SDFNeuralField(\n",
    "    in_channels=3,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    hidden_size_x=HIDDEN_SIZE_X,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    num_cond_blocks=NUM_COND_BLOCKS,\n",
    "    nerf_mlp_ratio=NERF_MLP_RATIO,\n",
    "    max_freqs=MAX_FREQS,\n",
    ").to(DEVICE)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"SDF Model Parameters: {n_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(2, N_POINTS, 3, device=DEVICE)\n",
    "test_t = torch.rand(2, device=DEVICE)\n",
    "\n",
    "# Test SDF output\n",
    "with torch.no_grad():\n",
    "    sdf_out = model.forward_sdf(test_input, test_t)\n",
    "print(f\"SDF output shape: {sdf_out.shape} (scalar per point)\")\n",
    "\n",
    "# Test velocity output (via gradient)\n",
    "vel_out = model.get_velocity(test_input, test_t)\n",
    "print(f\"Velocity output shape: {vel_out.shape} (derived from -∇f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "loss_fn = SDFFlowMatchingLoss(schedule_type='linear', eikonal_weight=EIKONAL_WEIGHT)\n",
    "sampler = FlowMatchingSampler(model)\n",
    "\n",
    "train_losses = []\n",
    "velocity_losses = []\n",
    "epoch_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_vel_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x0 = batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = loss_fn(model, x0)\n",
    "        loss = output['loss']\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_vel_loss += output['velocity_loss']\n",
    "        n_batches += 1\n",
    "    \n",
    "    return total_loss / n_batches, total_vel_loss / n_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_samples(model, sampler, n_samples=4, n_points=256, n_steps=50, device='cpu'):\n",
    "    model.eval()\n",
    "    noise = torch.randn(n_samples, n_points, 3, device=device)\n",
    "    samples = sampler.sample_euler(noise, n_steps=n_steps)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(f\"Training SDF model for {EPOCHS} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pbar = tqdm(range(EPOCHS), desc=\"Training SDF\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    start_time = time.time()\n",
    "    loss, vel_loss = train_epoch(model, dataloader, optimizer, loss_fn, DEVICE)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    velocity_losses.append(vel_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    pbar.set_postfix({'loss': f'{loss:.4f}', 'vel': f'{vel_loss:.4f}'})\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f} | Vel: {vel_loss:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Final loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Average epoch time: {np.mean(epoch_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Total')\n",
    "plt.plot(velocity_losses, label='Velocity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SDF Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses[10:])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss (after warmup)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "print(\"Generating samples from SDF model...\")\n",
    "samples = generate_samples(model, sampler, n_samples=8, n_points=N_POINTS, \n",
    "                           n_steps=50, device=DEVICE)\n",
    "samples = samples.cpu().numpy()\n",
    "print(f\"Generated {samples.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GT vs Generated\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    gt = dataset[i].numpy()\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection='3d')\n",
    "    ax.scatter(gt[:, 0], gt[:, 1], gt[:, 2], s=2, alpha=0.5, c='blue')\n",
    "    ax.set_title(f'Ground Truth {i+1}')\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.set_zlim([-1.5, 1.5])\n",
    "\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(2, 4, i + 5, projection='3d')\n",
    "    ax.scatter(samples[i, :, 0], samples[i, :, 1], samples[i, :, 2], \n",
    "               s=2, alpha=0.5, c='red')\n",
    "    ax.set_title(f'Generated {i+1}')\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.set_zlim([-1.5, 1.5])\n",
    "\n",
    "plt.suptitle('SDF Model: GT (blue) vs Generated (red)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Visualize Learned SDF\n",
    "\n",
    "One advantage of the SDF approach: we can visualize the learned distance field at t=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_sdf_slices(model, device, resolution=50):\n",
    "    \"\"\"Visualize SDF at different z-slices.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    x = torch.linspace(-1.5, 1.5, resolution)\n",
    "    y = torch.linspace(-1.5, 1.5, resolution)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing='ij')\n",
    "    \n",
    "    z_slices = [-0.5, 0.0, 0.5]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(z_slices), figsize=(15, 5))\n",
    "    \n",
    "    for idx, z_val in enumerate(z_slices):\n",
    "        zz = torch.full_like(xx, z_val)\n",
    "        points = torch.stack([xx.flatten(), yy.flatten(), zz.flatten()], dim=-1)\n",
    "        points = points.unsqueeze(0).to(device)\n",
    "        \n",
    "        t = torch.zeros(1, device=device)\n",
    "        sdf = model.get_sdf(points, t)\n",
    "        sdf = sdf.squeeze().cpu().numpy().reshape(resolution, resolution)\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        im = ax.contourf(xx.numpy(), yy.numpy(), sdf, levels=20, cmap='RdBu')\n",
    "        ax.contour(xx.numpy(), yy.numpy(), sdf, levels=[0], colors='black', linewidths=2)\n",
    "        ax.set_title(f'SDF at z={z_val:.1f}')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_aspect('equal')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    plt.suptitle('Learned SDF at t=0 (black contour = zero level set)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sdf_slices(model, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Resolution Independence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test unconditional generation at different resolutions\n",
    "print(\"Testing resolution independence (SDF model)...\")\n",
    "\n",
    "resolutions = [64, 128, 256, 512, 1024]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i, n_pts in enumerate(resolutions):\n",
    "    noise = torch.randn(1, n_pts, 3, device=DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        sample = sampler.sample_euler(noise, n_steps=50)\n",
    "    \n",
    "    sample = sample.cpu().numpy()[0]\n",
    "    \n",
    "    ax = fig.add_subplot(1, 5, i + 1, projection='3d')\n",
    "    ax.scatter(sample[:, 0], sample[:, 1], sample[:, 2], \n",
    "               s=max(1, 5 - i), alpha=0.5, c='green')\n",
    "    ax.set_title(f'N = {n_pts}')\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.set_zlim([-1.5, 1.5])\n",
    "    \n",
    "    print(f\"  Generated {n_pts:5d} points\")\n",
    "\n",
    "plt.suptitle('SDF Model Resolution Independence', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### SDF-Based Approach:\n",
    "\n",
    "1. **Model outputs scalar**: f(x,t) ∈ ℝ instead of v(x,t) ∈ ℝ³\n",
    "\n",
    "2. **Velocity via gradient**: v(x,t) = -∇_x f(x,t) computed by autograd\n",
    "\n",
    "3. **Smoother training**: Scalar field gradients are naturally continuous\n",
    "\n",
    "4. **Implicit surface**: At t=0, the zero level set f(x,0)=0 represents the learned shape\n",
    "\n",
    "### Comparison to Direct Velocity:\n",
    "\n",
    "| Aspect | Direct Velocity | SDF-Based |\n",
    "|--------|----------------|------------|\n",
    "| Output | v(x,t) ∈ ℝ³ | f(x,t) ∈ ℝ |\n",
    "| Training | May have discontinuities | Smoother gradients |\n",
    "| Surface representation | Implicit via flow | Explicit SDF |\n",
    "| Computation | Direct forward | Forward + autograd |\n",
    "\n",
    "### When to use SDF:\n",
    "- Training is unstable with direct velocity\n",
    "- You want to visualize/use the learned SDF\n",
    "- You need guaranteed smooth velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "shapes_str = '_'.join(SHAPES)\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': {\n",
    "        'hidden_size': HIDDEN_SIZE,\n",
    "        'hidden_size_x': HIDDEN_SIZE_X,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'num_blocks': NUM_BLOCKS,\n",
    "        'num_cond_blocks': NUM_COND_BLOCKS,\n",
    "        'nerf_mlp_ratio': NERF_MLP_RATIO,\n",
    "        'max_freqs': MAX_FREQS,\n",
    "    },\n",
    "    'train_losses': train_losses,\n",
    "    'shapes': SHAPES,\n",
    "    'n_points': N_POINTS,\n",
    "    'model_type': 'SDFNeuralField',\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, f'../experiments/outputs/sdf_notebook_checkpoint_{shapes_str}.pt')\n",
    "print(f\"Saved SDF checkpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
